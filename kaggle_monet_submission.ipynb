{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2de995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Boilerplate & Environment Check\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7363e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess Photos (Resize to 256x256)\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def load_images(image_paths, size=(256, 256)):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=size)\n",
    "        img = img_to_array(img)\n",
    "        img = (img / 127.5) - 1\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "photo_paths = glob('/kaggle/input/gan-getting-started/photo_jpg/*.jpg')[:8000]  # Limit to 8000\n",
    "photos = load_images(photo_paths)\n",
    "print(\"Loaded\", len(photos), \"photos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and Load Pretrained Generator Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_generator():\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2DTranspose(3, (4, 4), strides=2, padding='same', activation='tanh')(x)\n",
    "    return Model(inputs, x, name=\"Generator\")\n",
    "\n",
    "gen = build_generator()\n",
    "# gen.load_weights('/kaggle/input/your-model-folder/gen_weights.h5')\n",
    "print(\"✅ Generator model is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b88802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate Monet-Style Images\n",
    "from PIL import Image\n",
    "\n",
    "output_dir = \"/kaggle/working/generated_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(7000):  # Must be between 7000–10000\n",
    "    idx = i % len(photos)\n",
    "    sample = np.expand_dims(photos[idx], axis=0)\n",
    "    fake = gen(sample, training=False).numpy()[0]\n",
    "    fake = ((fake + 1) * 127.5).astype(np.uint8)\n",
    "    img = Image.fromarray(fake)\n",
    "    img = img.resize((256, 256))\n",
    "    img.save(f\"{output_dir}/{i:05}.jpg\")\n",
    "\n",
    "print(\"✅ 7000 Monet-style images generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip for Submission\n",
    "import zipfile\n",
    "\n",
    "zipf = zipfile.ZipFile(\"/kaggle/working/images.zip\", 'w', zipfile.ZIP_DEFLATED)\n",
    "for root, _, files in os.walk(output_dir):\n",
    "    for file in files:\n",
    "        zipf.write(os.path.join(root, file), file)\n",
    "zipf.close()\n",
    "\n",
    "print(\"✅ images.zip ready for submission.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
